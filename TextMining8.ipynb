{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504cf230-8e98-4d10-be87-dcd727d16c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#review count: 2000\n",
      "#samples of file ids: ['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n",
      "#categories of reviews: ['neg', 'pos']\n",
      "#num of \"neg\" reviews: 1000\n",
      "#num of \"pos\" reviews: 1000\n",
      "#id of the first review: neg/cv000_29416.txt\n",
      "#part of the first review: plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . . . \n",
      "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
      "which is what makes this review an even harder one to write , since i generally applaud films which attempt\n",
      "#sentiment of the first review: ['neg']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print('#review count:', len(movie_reviews.fileids())) #영화 리뷰 문서의 id를 반환\n",
    "print('#samples of file ids:', movie_reviews.fileids()[:10]) #id를 10개까지만 출력\n",
    "print('#categories of reviews:', movie_reviews.categories()) # label, 즉 긍정인지 부정인지에 대한 분류\n",
    "print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) #label이 부정인 문서들의 id를 반환\n",
    "print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) #label이 긍정인 문서들의 id를 반환\n",
    "\n",
    "fileid = movie_reviews.fileids()[0] #첫번째 문서의 id를 반환\n",
    "print('#id of the first review:', fileid)\n",
    "print('#part of the first review:', movie_reviews.raw(fileid)[:500]) #첫번째 문서의 내용을 500자까지만 출력\n",
    "print('#sentiment of the first review:', movie_reviews.categories(fileid)) #첫번째 문서의 감성\n",
    "\n",
    "fileids = movie_reviews.fileids() #movie review data에서 file id를 가져옴\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids] #file id를 이용해 raw text file을 가져옴\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f15f6e-27b8-48bf-8273-1bacd4ab8dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\jupit\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\jupit\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jupit\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jupit\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jupit\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jupit\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 81.9/626.3 kB 1.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 143.4/626.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 174.1/626.3 kB 1.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 174.1/626.3 kB 1.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 327.7/626.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 389.1/626.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 450.6/626.3 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 491.5/626.3 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 501.8/626.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 626.3/626.3 kB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.18.0.post0\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab820e6-bc5f-4c7c-8e84-56b2c420f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.06479782948532947, subjectivity=0.5188408350908352)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "result = TextBlob(reviews[0])\n",
    "print(result.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdc07e6-2167-4aee-93fd-a1f42351719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_TextBlob(docs):\n",
    "    results = []\n",
    "\n",
    "    for doc in docs:\n",
    "        testimonial = TextBlob(doc)\n",
    "        if testimonial.sentiment.polarity > 0:\n",
    "            results.append('pos')\n",
    "        else:\n",
    "            results.append('neg')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cbd91b-79eb-4e8f-b68a-4877ee9bd816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TextBlob을 이용한 리뷰 감성분석의 정확도: 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('#TextBlob을 이용한 리뷰 감성분석의 정확도:', accuracy_score(categories, sentiment_TextBlob(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22763253-4eb0-4561-abb9-0ec323861086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "     ---------------------------------------- 0.0/52.6 kB ? eta -:--:--\n",
      "     -------------------------------------- - 51.2/52.6 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 52.6/52.6 kB 920.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py): started\n",
      "  Building wheel for afinn (setup.py): finished with status 'done'\n",
      "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53438 sha256=693f17f484b80eafc2649ae33e96fdecd2927977b373571283773c852cbdc569\n",
      "  Stored in directory: c:\\users\\jupit\\appdata\\local\\pip\\cache\\wheels\\f9\\72\\27\\74994e77200dae3d6aea2b546264500cee21f738c51241320b\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545044f7-3720-4425-a2ec-d80055792e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Afinn을 이용한 리뷰 감성분석의 정확도: 0.664\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "def sentiment_Afinn(docs):\n",
    "    afn = Afinn(emoticons=True)\n",
    "    results = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if afn.score(doc) > 0:\n",
    "            results.append('pos')\n",
    "        else:\n",
    "            results.append('neg')\n",
    "    return results\n",
    "\n",
    "print('#Afinn을 이용한 리뷰 감성분석의 정확도:', accuracy_score(categories, sentiment_Afinn(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca3e0bc3-1ef5-4820-8d38-3691edbaf9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jupit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fb3b64-2092-4396-88fd-02f084e67830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Vader을 이용한 리뷰 감성분석의 정확도: 0.635\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def sentiment_vader(docs):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    results = []\n",
    "\n",
    "    for doc in docs:\n",
    "        score = analyser.polarity_scores(doc)\n",
    "        if score['compound'] > 0:\n",
    "            results.append('pos')\n",
    "        else:\n",
    "            results.append('neg')\n",
    "\n",
    "    return results\n",
    "\n",
    "print('#Vader을 이용한 리뷰 감성분석의 정확도:', accuracy_score(categories, sentiment_vader(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47935449-0cc7-4447-9729-792e836eb360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set count:  1600\n",
      "Test set count:  400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split #sklearn에서 제공하는 split 함수를 사용\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, categories, test_size=0.2, random_state=7)\n",
    "\n",
    "print('Train set count: ', len(X_train))\n",
    "print('Test set count: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b7030f7-9a1c-4f58-ad17-9287c30020d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set dimension: (1600, 36189)\n",
      "#Test set dimension: (400, 36189)\n",
      "#Train set score: 0.998\n",
      "#Test set score: 0.797\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB #sklearn이 제공하는 MultinomialNB 를 사용\n",
    "\n",
    "tfidf = TfidfVectorizer().fit(X_train) \n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train) # train set을 변환\n",
    "print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "print('#Test set dimension:', X_test_tfidf.shape)\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언\n",
    "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b45f8-da92-444b-b8ec-b7ceafb101d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
